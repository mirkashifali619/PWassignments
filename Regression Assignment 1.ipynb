{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e799af1d",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each.\n",
    "ANS : Simple linear regression and multiple linear regression are both types of regression analysis used to model the relationship between a dependent variable and one or more independent variables. The main difference between the two is the number of independent variables:\n",
    "Simple linear regression: This model has one independent variable and one dependent variable. The equation is y = a + bx, where y is the dependent variable, x is the independent variable, a is the intercept, and b is the slope.\n",
    "Multiple linear regression: This model has one dependent variable and two or more independent variables. The equation is y = a + b1x1 + b2x2 + ... + bnxn, where y is the dependent variable, x1, x2, ..., xn are the independent variables, a is the intercept, and b1, b2, ..., bn are the slopes.\n",
    "\n",
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?\n",
    "ANS:  The assumptions of linear regression include:\n",
    "The dependent variable should be continuous.\n",
    "There should be a linear relationship between the dependent variable and each independent variable.\n",
    "The data should have homoscedasticity, meaning the variance of the dependent variable should be constant across all levels of the independent variable.\n",
    "The data should be normally distributed.\n",
    "To check whether these assumptions hold in a given dataset, you can:\n",
    "Plot scatterplots to visualize the relationship between the dependent variable and each independent variable.\n",
    "Check for homoscedasticity by plotting residuals against predicted values.\n",
    "Use statistical tests, such as the Shapiro-Wilk test, to check for normality.\n",
    "\n",
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario.\n",
    "ANS: . In a linear regression model, the slope (b) represents the change in the dependent variable for a one-unit change in the independent variable, holding all other independent variables constant. The intercept (a) represents the value of the dependent variable when all independent variables are equal to zero.\n",
    "For example, consider a real-world scenario where you want to predict the price of a house based on its square footage and the number of bedrooms. The square footage is the independent variable (x1), the number of bedrooms is the independent variable (x2), and the house price is the dependent variable (y). The equation would be:\n",
    "y = a + b1x1 + b2x2\n",
    "In this case, the slope b1 represents the change in house price for a one-unit increase in square footage, holding the number of bedrooms constant. The slope b2 represents the change in house price for a one-unit increase in the number of bedrooms, holding square footage constant. The intercept a represents the expected house price when both square footage and the number of bedrooms are equal to zero.\n",
    "\n",
    "Q4.Explain the concept of gradient descent. How is it used in machine learning?\n",
    "ANS: Gradient descent is an optimization algorithm used in machine learning to find the minimum of a function. It works by iteratively adjusting the parameters of a model to minimize the loss function, which is a measure of how well the model fits the data. Gradient descent is particularly useful for training neural networks and other complex models.\n",
    "\n",
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "ANS: The multiple linear regression model is an extension of the simple linear regression model that includes multiple independent variables. It allows for the analysis of more complex relationships between the dependent variable and multiple independent variables. The main difference between simple and multiple linear regression is the number of independent variables: simple linear regression has one independent variable, while multiple linear regression has two or more independent variables.\n",
    "\n",
    "Q6.Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?\n",
    "ANS: Multicollinearity is a situation where two or more independent variables in a multiple linear regression model are highly correlated with each other. This can lead to unstable estimates of the model's coefficients and reduced statistical power. To detect multicollinearity, you can calculate the variance inflation factor (VIF) for each independent variable. If the VIF is greater than 10, it indicates multicollinearity. To address multicollinearity, you can remove one of the highly correlated independent variables or combine them into a single variable.\n",
    "\n",
    "Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "ANS :  The polynomial regression model is a type of regression analysis that extends the simple linear regression model to include polynomial terms. This allows for the analysis of non-linear relationships between the dependent variable and one or more independent variables. For example, a quadratic polynomial regression model would have the form y = a + bx + cx^2, where x is the independent variable and y is the dependent variable.\n",
    "\n",
    "Q8.  What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?\n",
    "ANS : The advantages of polynomial regression over linear regression include:\n",
    "Ability to model non-linear relationships between the dependent variable and independent variables.\n",
    "Improved fit for data with non-linear patterns.\n",
    "However, polynomial regression also has some disadvantages:\n",
    "Increased complexity, which can make the model more difficult to interpret.\n",
    "Increased risk of overfitting, especially when using high-degree polynomials.\n",
    "You would prefer to use polynomial regression when you suspect a non-linear relationship between the dependent variable and independent variables, and when linear regression does not provide a satisfactory fit."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
